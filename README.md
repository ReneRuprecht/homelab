# ğŸ  Homelab
# âœ¨ Intro
Das Repository dokumentiert mein selbst gehostetes Homelab basierend auf Proxmox und Kubernetes. 
Ziel ist es, verschiedene Technologien, Tools und Konzepte durch praktische Erfahrungen besser zu verstehen. 
Dabei versuche ich, so viel wie mÃ¶glich zu automatisieren und die gesamte Infrastruktur als Code abzubilden.


# ğŸ’» Hardware
Die eingesetzte Hardware befindet sich in einem selbstgebauten 10" Rack. 
- Beelink S12 Mini Pro mit 32â€¯GB RAM, einer 1 TB SSD und einer 256â€¯GB NVMe zum Einsatz (Proxmox). 
- Lenovo M720q mit 48â€¯GB RAM, einer 512â€¯GB SSD und einer 256â€¯GB NVMe zum Einsatz (Proxmox). 

# ğŸ–¥ï¸ Proxmox
Die VMs werden mit Terraform erstellt. Dabei werden grundlegende Ressourcen wie CPU, RAM, Netzwerk und Speicher definiert und anschlieÃŸend in Proxmox bereitgestellt. Die Installation und Konfiguration der Software Ã¼bernimmt Ansible. Mithilfe von Ansible Playbooks wird die benÃ¶tigte Software sowie deren Konfiguration konsistent eingerichtet und bereitgestellt.

# ğŸ›³ï¸ Kubernetes
Das laufende Kubernetes Cluster soll, soweit mÃ¶glich, vollstÃ¤ndig mittels GitOps ausgestattet und konfiguriert werden. Geplant ist, interne Services wie Prometheus und Grafana mit FluxCD zu deployen und zu verwalten, wÃ¤hrend eigene Apps und Services Ã¼ber ArgoCD bereitgestellt und gemanagt werden. Ziel ist es, anhand praktischer Beispiele ein besseres VerstÃ¤ndnis fÃ¼r beide Systeme zu entwickeln.

## â›µ ArgoCD
ArgoCD wird verwendet um Anwendungen automatisch aus der Repository auf dem Kubernetes zu deployen.

# ğŸš€ Pipeline

Die Pipeline wird dafÃ¼r genutzt das, sofern mÃ¶glich, alle deployments automatisiert ausgefÃ¼hrt werden.
DafÃ¼r existieren speziell vorbereitete Docker-Images, die jeweils in den einzelnen Schritten genutzt werden.  

Die Pipeline prÃ¼ft, ob sich in den definierten Pfaden Ã„nderungen ergeben haben. Werden Ã„nderungen erkannt, erscheinen diese in der Ãœbersicht.

## ğŸ³ Docker

- Ã„nderungen an den Dockerfiles fÃ¼hren automatisch zum Neubau der Images.  
- Die neuen Images werden anschlieÃŸend in das Registry/Hub gepusht.  

## âš™ï¸ Ansible

- Ã„nderungen in den Ansible-Dateien (z. B. Host-/Group-Vars) fÃ¼hren zur AusfÃ¼hrung der betroffenen Playbooks.  
- Die Zuordnung erfolgt Ã¼ber die Datei `playbook_mapping.yml` im Ansible-Ordner.  
- **Reihenfolge:** Das DNS-Playbook wird immer zuerst ausgefÃ¼hrt, damit die VM erreichbar ist.  

### Wichtig
- Playbooks werden **nur beim Merge auf den `main`-Branch** ohne `--check` ausgefÃ¼hrt.  
- Logs werden verschlÃ¼sselt als Artifact gespeichert.  

## ğŸŒ Terraform

- Ã„nderungen in den Terraform-Konfigurationen fÃ¼hren zur Erstellung oder Anpassung der betroffenen VMs.  
- Vorab wird eine Ãœbersicht erstellt, in der sichtbar ist, ob Ressourcen hinzugefÃ¼gt, geÃ¤ndert oder entfernt werden.  
- Der Plan-Output wird â€“ wie bei Ansible â€“ verschlÃ¼sselt als Artifact hochgeladen.  

### Wichtig
- `terraform apply` wird **nur beim Merge auf den `main`-Branch** ausgefÃ¼hrt.  

# ğŸ”§ Services

Aktuell wird eine Kombination aus virtuellen Maschinen und Kubernetes-Services betrieben.
Die Umgebunj wird kontinuierlich weiterentwickelt und angepasst.

## Virtuelle Maschinen (VMs)
- 3Ã— **Consul**, Terraform State fÃ¼r die Pipeline
- 2Ã— **DNS**
- 2Ã— **Github Runner**, fÃ¼r die Pipeline
- 3Ã— **Vault**, die derzeit fÃ¼r Kubernetes-Secrets verwendet werden  
- 2Ã— **Loadbalancer**, der Anfragen z.B. an die Vault-Instanzen weiterleitet  
- 3Ã— **K8s** (1 Master und 2 Nodes)  
- 1Ã— **Netbox**, fÃ¼r die Dokumentation
- 1Ã— **Monitoring**, fÃ¼r Prometheus, Grafana
- 1Ã— **Keycloak**, fÃ¼r Grafana und ArgoCD 

## Kubernetes-Services
- **FluxCD**  
- **External Secrets**  
- **Longhorn**  

# ğŸ¤– Ansible
FÃ¼r die VMs im Homelab wurden und werden eigene Ansible Rollen entwickelt. 
Hierzu zÃ¤hlt z.B. eine `General` Rolle die VMs mit den Basic Settings ausstattet (ssh, firewall, hostname, ... ) oder 
eine `HAProxy` Rolle die es mÃ¶glich macht mittels url auf verschiedene Backends zu routen.
Jede VM sollte die `General`, `Consul`, `Promtail`, `Node_Exporter` Rolle im Playbook haben damit die Grundeinstellung gesetzt ist.

## Rollen
- General
- Kubernetes
- HAProxy

# ğŸ›¡ï¸ Monitoring
Aktuell wird eine VM mit Prometheus, Grafana und Loki verwendet.
Auf den VMs wird per Promtail die Logs gesammelt und an Loki gesendet.
Dazu gibt es verschiedene Exporter die Prometheus mit Daten versorgen.

## Prometheus
In Prometheus werden VMs automatisch Ã¼ber Consul und Service Discovery aufgenommen.

## Exporter
- `Node Exporter` auf allen VMs
- `Bind Exporter` auf DNS VMs
- `Consul Exporter` auf Consul VMs
  
# ğŸ› ï¸ Configs
## Ansible
Im Ansible-Ordner befindet sich die Pipfile, welche mit dem Befehl ```pipenv shell``` aktiviert werden kann. Fehlende Python Pakete lassen sich anschlieÃŸend mit ```pipenv install --dev``` installieren. Um die benÃ¶tigten Ansible Collections und Rollen zu installieren, kann ```ansible-galaxy install -r requirements.yml``` verwendet werden.

## Terraform
### Netbox
```sh
export NETBOX_SERVER_URL=<URL>
export NETBOX_API_TOKEN=<TOKEN>

export TF_VAR_netbox_url=<URL>
export TF_VAR_netbox_token=<TOKEN>
```
### Proxmox
FÃ¼r die Verbindung zum Proxmox werden folgende Environment Variablen benÃ¶tigt.
```sh
export PM_API_URL=<URL>
export PM_API_TOKEN_ID=<ID>
export PM_API_TOKEN_SECRET=<SECRET>
```
### VMs
FÃ¼r die Erstellung von VMs werden folgende Environment Variablen benÃ¶tigt.
```sh
export TF_VAR_vm_user=<vm_user>
export TF_VAR_vm_ssh_keys=<ssh_keys>
```

### Rack
![alt text](./images/rack.png "Rack")
![alt text](./images/beelink.png "Beelink")
